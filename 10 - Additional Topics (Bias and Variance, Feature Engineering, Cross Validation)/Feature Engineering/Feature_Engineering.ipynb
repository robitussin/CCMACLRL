{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvFWei2mAxSH"
      },
      "source": [
        "# Feature Engineering\n",
        "\n",
        "Feature engineering is one of the most important aspects of the machine learning pipeline. It is the practice of creating and modifying features, or variables, for the purposes of improving model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7G7VcbLVBA26"
      },
      "source": [
        "## What are Features?\n",
        "\n",
        "Features are measurable characteristics of any phenomenon that we are observing. They are the granular elements that make up the data with which models operate upon to make predictions. Examples of features can include things like age, income, a timestamp, longitude, value, and almost anything else one can think of that can be measured or represented in some form.\n",
        "\n",
        "There are different feature types, the main ones being:\n",
        "\n",
        "1. **Numerical Features**: Continuous or discrete numeric types (e.g. age, salary)\n",
        "2. **Categorical Features**: Qualitative values representing categories (e.g. gender, shoe size type)\n",
        "3. **Text Features**: Words or strings of words (e.g. \"this\" or \"that\" or \"even this\")\n",
        "4. **Time Series Features**: Data that is ordered by time (e.g. stock prices)\n",
        "\n",
        "Features are crucial in machine learning because they directly influence a model's ability to make predictions. Well-constructed features improve model performance, while bad features make it harder for a model to produce strong predictions. Feature selection and feature engineering are preprocessing steps in the machine learning process that are used to prepare the data for use by learning algorithms.\n",
        "\n",
        "A distinction is made between feature selection and feature engineering, though both are crucial in their own right:\n",
        "\n",
        "1. **Feature Selection**: The culling of important features from the entire set of all available features, thus reducing dimensionality and promoting model performance\n",
        "2. **Feature Engineering**: The creation of new features and subsequent changing of existing ones, all in the aid of making a model perform better\n",
        "By selecting only the most important features, feature selection helps to only leave behind the signal in the data, while feature engineering creates new features that help to model the outcome better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j32_JEkABiuk"
      },
      "source": [
        "## Handling Missing Values\n",
        "It is common for datasets to contain missing information. This can be detrimental to a model's performance, which is why it is important to implement strategies for dealing with missing data. There are a handful of common methods for rectifying this issue:\n",
        "\n",
        "1. **Mean/Median Imputation**: Filling missing areas in a dataset with the mean or median of the column\n",
        "2. **Mode Imputation**: Filling missing spots in a dataset with the most common entry in the same column\n",
        "3. **Interpolation**: Filling in missing data with values of data points around it\n",
        "These fill-in methods should be applied based on the nature of the data and the potential effect that the method might have on the end model.\n",
        "\n",
        "Dealing with missing information is crucial in keeping the integrity of the dataset in tact. Here is an example Python code snippet that demonstrates various data filling methods using the pandas library."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TAYJE3-JAvsN",
        "outputId": "3b17b584-0ce0-4cfe-d27b-419446f6d702"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    age   salary\n",
            "0  25.0  50000.0\n",
            "1  30.0  60000.0\n",
            "2   NaN  55000.0\n",
            "3  35.0      NaN\n",
            "4  40.0  65000.0\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {'age': [25, 30, np.nan, 35, 40], 'salary': [50000, 60000, 55000, np.nan, 65000]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "age       1\n",
              "salary    1\n",
              "dtype: int64"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FI-ETwS0BxHO",
        "outputId": "ce090180-97e1-400f-95e5-704037351b98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    age   salary\n",
            "0  25.0  50000.0\n",
            "1  30.0  60000.0\n",
            "2  32.5  55000.0\n",
            "3  35.0  57500.0\n",
            "4  40.0  65000.0\n"
          ]
        }
      ],
      "source": [
        "# Fill in missing ages using the mean\n",
        "mean_imputer = SimpleImputer(strategy='mean')\n",
        "df['age'] = mean_imputer.fit_transform(df[['age']])\n",
        "\n",
        "# Fill in the missing salaries using the median\n",
        "median_imputer = SimpleImputer(strategy='median')\n",
        "df['salary'] = median_imputer.fit_transform(df[['salary']])\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2PB0FSskB4WJ"
      },
      "source": [
        "## Encoding of Categorical Variables\n",
        "Recalling that most machine learning algorithms are best (or only) equipped to deal with numeric data, categorical variables must often be mapped to numerical values in order for said algorithms to better interpret them. The most common encoding schemes are the following:\n",
        "\n",
        "1. **One-Hot Encoding**: Producing separate columns for each category\n",
        "2. **Label Encoding**: Assigning an integer to each category\n",
        "3. **Target Encoding**: Encoding categories by their individual outcome variable averages\n",
        "The encoding of categorical data is necessary for planting the seeds of understanding in many machine learning models. The right encoding method is something you will select based on the specific situation, including both the algorithm at use and the dataset.\n",
        "\n",
        "Below is an example Python script for the encoding of categorical features using pandas and elements of scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "thSlXLJ-CA9a",
        "outputId": "45d22f89-21e9-4019-d68f-d4a3a4b48ba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   color\n",
            "0    red\n",
            "1   blue\n",
            "2  green\n",
            "3   blue\n",
            "4    red\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {'color': ['red', 'blue', 'green', 'blue', 'red']}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wii8N99PCLO9",
        "outputId": "bf0007d0-e589-43dd-88fb-2311ccc8fc0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   color_blue  color_green  color_red\n",
            "0         0.0          0.0        1.0\n",
            "1         1.0          0.0        0.0\n",
            "2         0.0          1.0        0.0\n",
            "3         1.0          0.0        0.0\n",
            "4         0.0          0.0        1.0\n"
          ]
        }
      ],
      "source": [
        "# Implementing one-hot encoding\n",
        "one_hot_encoder = OneHotEncoder()\n",
        "one_hot_encoding = one_hot_encoder.fit_transform(df[['color']]).toarray()\n",
        "df_one_hot = pd.DataFrame(one_hot_encoding, columns=one_hot_encoder.get_feature_names_out(['color']))\n",
        "print(df_one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGvbpHElCah0",
        "outputId": "b2889761-86f5-44ee-d8b2-b09de4400618"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   color  color_label\n",
            "0    red            2\n",
            "1   blue            0\n",
            "2  green            1\n",
            "3   blue            0\n",
            "4    red            2\n"
          ]
        }
      ],
      "source": [
        "# Implementing label encoding\n",
        "label_encoder = LabelEncoder()\n",
        "df['color_label'] = label_encoder.fit_transform(df['color'])\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_NYnVs7oFAWh",
        "outputId": "8cf8e0f3-c879-4797-cffc-72349d595cf7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     brand          damage\n",
            "0   iphone  cracked screen\n",
            "1  samsung            dent\n",
            "2     vivo           water\n",
            "3   xiaomi            dent\n"
          ]
        }
      ],
      "source": [
        "# Sample DataFrame\n",
        "data = {'brand': ['iphone', 'samsung', 'vivo', 'xiaomi'], 'damage': ['cracked screen', 'dent', 'water', 'dent']}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Lk0X1c5FlQI",
        "outputId": "6b565238-d847-458e-bd46-d7e5ada7d115"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     brand  damage\n",
            "0   iphone       0\n",
            "1  samsung       1\n",
            "2     vivo       2\n",
            "3   xiaomi       1\n"
          ]
        }
      ],
      "source": [
        "df['damage'] = df['damage'].map({'cracked screen': 0,'dent': 1, 'water': 2})\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CnRuISaCjk1"
      },
      "source": [
        "## Scaling and Normalizing Data\n",
        "For good performance of many machine learning methods, scaling and normalization needs to be performed on your data. There are several methods for scaling and normalizing data, such as:\n",
        "\n",
        "1. Standardization: Transforming data so that it has a mean of 0 and a standard deviation of 1\n",
        "2. Min-Max Scaling: Scaling data to a fixed range, such as [0, 1]\n",
        "3. Robust Scaling: Scaling high and low values iteratively by the median and interquartile range, respectively\n",
        "The scaling and normalization of data is crucial for ensuring that feature contributions are equitable. These methods allow the varying feature values to contribute to a model commensurately.\n",
        "\n",
        "Below is an implementation, using scikit-learn, that shows how to complete data that has been scaled and normalized."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bxu78c0uCqIc",
        "outputId": "becdd051-bea5-4e3c-cbff-ede3540b8246"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   age  salary\n",
            "0   25   50000\n",
            "1   30   60000\n",
            "2   35   55000\n",
            "3   40   65000\n",
            "4   45   70000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\n",
        "\n",
        "# Sample DataFrame\n",
        "data = {'age': [25, 30, 35, 40, 45], 'salary': [50000, 60000, 55000, 65000, 70000]}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-PKPDguCt6L",
        "outputId": "c21b8f37-5b42-41e9-d9cc-f5ec93535f7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   age  salary  age_standard  salary_minmax  salary_robust\n",
            "0   25   50000     -1.414214           0.00           -1.0\n",
            "1   30   60000     -0.707107           0.50            0.0\n",
            "2   35   55000      0.000000           0.25           -0.5\n",
            "3   40   65000      0.707107           0.75            0.5\n",
            "4   45   70000      1.414214           1.00            1.0\n"
          ]
        }
      ],
      "source": [
        "# Standardize data\n",
        "scaler_standard = StandardScaler()\n",
        "df['age_standard'] = scaler_standard.fit_transform(df[['age']])\n",
        "\n",
        "# Min-Max Scaling\n",
        "scaler_minmax = MinMaxScaler()\n",
        "df['salary_minmax'] = scaler_minmax.fit_transform(df[['salary']])\n",
        "\n",
        "# Robust Scaling\n",
        "scaler_robust = RobustScaler()\n",
        "df['salary_robust'] = scaler_robust.fit_transform(df[['salary']])\n",
        "\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lUZJne9C9J3"
      },
      "source": [
        "## Advanced Techniques in Feature Engineering\n",
        "\n",
        "\n",
        "We now turn our attention to to more advanced featured engineering techniques, and include some sample Python code for implementing these concepts.\n",
        "\n",
        "\n",
        "### Feature Creation\n",
        "With feature creation, new features are generated or modified to fashion a model with better performance. Some techniques for creating new features include:\n",
        "\n",
        "1. **Polynomial Features**: Creation of higher-order features with existing features to capture more complex relationships\n",
        "2. **Interaction Terms**: Features generated by combining several features to derive interactions between them\n",
        "3. **Domain-Specific Feature Generation**: Features designed based on the intricacies of subjects within the given problem realm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iE2gQ7UyC67C",
        "outputId": "a549a62a-e192-45cb-f2a4-bcf0b6cd7cb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   x1  x2\n",
            "0   1  10\n",
            "1   2  20\n",
            "2   3  30\n",
            "3   4  40\n",
            "4   5  50\n"
          ]
        }
      ],
      "source": [
        "# Sample DataFrame\n",
        "data = {'x1': [1, 2, 3, 4, 5], 'x2': [10, 20, 30, 40, 50]}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7fSvqKuDTGx",
        "outputId": "ea83bc87-bc05-4a31-9387-e95b4e679dd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   x1  x2  x1_squared  x1_x2_interaction\n",
            "0   1  10           1                 10\n",
            "1   2  20           4                 40\n",
            "2   3  30           9                 90\n",
            "3   4  40          16                160\n",
            "4   5  50          25                250\n"
          ]
        }
      ],
      "source": [
        "# Polynomial Features\n",
        "df['x1_squared'] = df['x1'] ** 2\n",
        "df['x1_x2_interaction'] = df['x1'] * df['x2']\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_M9LkJNLLFq"
      },
      "source": [
        "Another example is extracting a feature or transforming a feature to a brand new feature. In this example, we can see that the model_nhame contains the RAM of the phone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vetwds9sH8Lj",
        "outputId": "b2ff0e82-597b-4f3e-c64e-e998cde3190d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     brand                    model_name  year_released\n",
            "0    Apple  Iphone Pro Max 16GB Titanium           2023\n",
            "1  Samsung        Samsung Galaxy S24 8GB           2024\n"
          ]
        }
      ],
      "source": [
        "# Sample DataFrame\n",
        "data = {'brand': ['Apple', 'Samsung'], 'model_name': ['Iphone Pro Max 16GB Titanium', 'Samsung Galaxy S24 8GB'], 'year_released':[2023, 2024]}\n",
        "df = pd.DataFrame(data)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWI8CtOBLgRy"
      },
      "source": [
        "We can create a new memory column which contains the amount of RAM of the phone. To extract it, we can use regex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfniJFgaJX0l",
        "outputId": "a149e0d2-082a-4fd8-f2f1-f0ca1c968ddf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     brand                    model_name  year_released  memory\n",
            "0    Apple  Iphone Pro Max 16GB Titanium           2023    16.0\n",
            "1  Samsung        Samsung Galaxy S24 8GB           2024     8.0\n"
          ]
        }
      ],
      "source": [
        "df['memory'] = df['model_name'].str.extract(r'(\\d+)(?=GB)').astype(float)\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yjnGPb37LsbC"
      },
      "source": [
        "We can also create a new 'phone_age' column by subtracting the current date and the release date of the phone"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSPoMugSLsqB",
        "outputId": "6d73eab4-c946-4669-a1eb-ac795fe4270d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "     brand                    model_name  year_released  memory  phone_age\n",
            "0    Apple  Iphone Pro Max 16GB Titanium           2023    16.0          2\n",
            "1  Samsung        Samsung Galaxy S24 8GB           2024     8.0          1\n"
          ]
        }
      ],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "current_year = datetime.now().year\n",
        "df['phone_age'] = current_year - df['year_released']\n",
        "print(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoTAJvlvDxBJ"
      },
      "source": [
        "## References\n",
        "\n",
        "https://www.kdnuggets.com/feature-engineering-for-beginners"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
